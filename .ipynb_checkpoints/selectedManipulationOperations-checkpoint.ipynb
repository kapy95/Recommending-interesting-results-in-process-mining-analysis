{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from interestingness_functions import normBoxScore\n",
    "from interestingness_functions import discretizeContinousVariable,indexNumericalValue,compaction\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPossibleGroups(log_ct,dataShapley,dispatcherKPI,case_id):\n",
    "    #scores=[]\n",
    "    groupsInfo={}\n",
    "    groups={}\n",
    "    for index, row in dataShapley.iterrows():\n",
    "        if row[\"binned\"]==False:\n",
    "            #group by the values of a feature\n",
    "#             group=log_ct.groupby(by=[case_id,row[\"Dimension\"][1]])\n",
    "#             score=compaction(group,log_ct.shape[0])\n",
    "            #Alternative version grouping depending on the values \n",
    "            traces_discrete_values=log_ct.groupby(case_id).apply(lambda x: x[row[\"Dimension\"][1]].unique()).reset_index()\n",
    "            val=row['concreteValue']\n",
    "            traces_with_value=[row[case_id] for index, row in traces_discrete_values.iterrows() if val in row[0]]\n",
    "            values=[True if row[case_id] in traces_with_value else False for index,row in log_ct.iterrows()]\n",
    "            log_ct['groupValue']=values\n",
    "            group=log_ct.groupby([\"groupValue\",row[\"Dimension\"][1]])\n",
    "            score=compaction(group,log_ct.shape[0])\n",
    "            \n",
    "            criteria=list(row['Dimension'])\n",
    "            criteria.append(row['function'])\n",
    "            criteria.append(row['interestValue'])\n",
    "            criteria.append(val)\n",
    "            criteria.append(\"groupTracesbyDiscreteAttribute\")\n",
    "            criteria.append(\"-\")\n",
    "            criteria.append(\"Conciseness\")\n",
    "            groupsInfo[tuple(criteria)]=score\n",
    "            groups[tuple(criteria)]=group\n",
    "            \n",
    "        else:\n",
    "            #group by the interval values of a feature\n",
    "#             dim=row[\"Dimension\"]\n",
    "#             fun=dispatcherKPI[dim[0]]\n",
    "#             dfs=log_ct.groupby(case_id).apply(lambda x: fun(x,dim[1],dim[2])).reset_index()\n",
    "#             labels,bins=indexNumericalValue(dfs,[0])\n",
    "#             intervals=[str(labels[0][np.where(labels[0].contains(val)==True)]) for val in dfs[0]]\n",
    "#             dfs['intervals']=intervals\n",
    "#             group=dfs.groupby([dim[1],\"intervals\"])\n",
    "            #group values depending on they are on the interval or not\n",
    "            dim=row['Dimension']\n",
    "            fun=dispatcherKPI[dim[0]]\n",
    "            val=interval_type(row['concreteValue'])\n",
    "            values_per_traces=log_ct.groupby(case_id).apply(lambda x: fun(x,dim[1],dim[2]))\n",
    "            case_ids_in_interval=[index for index,values in enumerate(values_per_traces) if values in val]\n",
    "            traces_state=[True if row[case_id] in case_ids_in_interval else False for index,row in log_ct.iterrows()]\n",
    "            log_ct['groupValue']=traces_state\n",
    "            group=log_ct.groupby([\"groupValue\",row[\"Dimension\"][1]])\n",
    "            \n",
    "            score=compaction(group,log_ct.shape[0])\n",
    "            #scores.append(score)\n",
    "            \n",
    "            criteria=list(row['Dimension'])\n",
    "            criteria.append(row['function'])\n",
    "            criteria.append(row['interestValue'])\n",
    "            criteria.append(str(val))\n",
    "            criteria.append(\"groupTracesbyNumericAttribute\")\n",
    "            criteria.append(\"-\")\n",
    "            criteria.append(\"Conciseness\")\n",
    "            groupsInfo[tuple(criteria)]=score\n",
    "            groups[tuple(criteria)]=group\n",
    "    \n",
    "    \n",
    "    scores=pd.Series(groupsInfo).reset_index()\n",
    "    scores[0]=normBoxScore(scores[0])\n",
    "    \n",
    "    return scores,groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative version of getpossible groups:\n",
    "# def getPossibleGroups(log_ct,dataShapley,dispatcherKPI,case_id):\n",
    "#     #ahora para cada filtro habría que calcular kullback y conciseness\n",
    "#     groups={}\n",
    "#     nrows=log_ct.shape[0]\n",
    "#     scores=[]\n",
    "#     for index, row in dataShapley.iterrows():\n",
    "#         numAtt=len(row['Dimension'][1:])\n",
    "#         numGroups=2#since it always groupby the existence of concrete values\n",
    "#         if row['binned']==True:\n",
    "#             interval=interval_type(row['concreteValue'])\n",
    "#             criteria=list(row['Dimension'])\n",
    "#             criteria.append(row['function'])\n",
    "#             criteria.append(str(interval))\n",
    "#             groupedCasesInRange,groupedCasesNotInRange=groupCasesNumericValues(log_ct,row['Dimension'],case_id,interval,dispatcherKPI)\n",
    "            \n",
    "#             criteria.append(\"groupCasesNumericValues\")\n",
    "#             if groupedCasesInRange.empty==False and groupedCasesNotInRange.empty==False:\n",
    "#                 groups[tuple(criteria)]=[groupedCasesInRange,groupedCasesNotInRange]\n",
    "#                 score=numAtt*numGroups\n",
    "#                 score=score/nrows\n",
    "#                 scores.append(score)\n",
    "                \n",
    "#         else:\n",
    "#             criteria=list(row['Dimension'])\n",
    "#             criteria.append(row['function'])\n",
    "#             criteria.append(row['concreteValue'])\n",
    "#             groupedCasesWithDiscreteValue,groupedCasesWithoutDiscreteValue=groupCasesDiscreteValue(log_ct,row['Dimension'],case_id,row['concreteValue'],dispatcherKPI)\n",
    "#             criteria.append(\"groupCasesDiscreteValues\")\n",
    "#             if groupedCasesWithDiscreteValue.empty==False and groupedCasesWithoutDiscreteValue.empty==False:\n",
    "#                 groups[tuple(criteria)]=[groupedCasesWithDiscreteValue,groupedCasesWithoutDiscreteValue]\n",
    "#                 score=numAtt*numGroups\n",
    "#                 score=score/nrows\n",
    "#                 scores.append(score)\n",
    "            \n",
    "#     #scores=normBoxScore(scores)   \n",
    "#     return groups,scores\n",
    "# groups,scores=getPossibleGroups(log_ct,dataShapley,dispatcherKPI,\"case:id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPossibleFilters(log_ct,dataShapley,dispatcherKPI,case_id):\n",
    "    #ahora para cada filtro habría que calcular kullback y conciseness\n",
    "    filters={}\n",
    "    \n",
    "    for index, row in dataShapley.iterrows():\n",
    "        if row['binned']==True:\n",
    "            interval=interval_type(row['concreteValue'])\n",
    "            criteria=list(row['Dimension'])\n",
    "            criteria.append(row['function'])\n",
    "            criteria.append(row['interestValue'])\n",
    "            criteria.append(str(interval))\n",
    "            filteredWithinRange=filterCasesWithinRange(log_ct,row['Dimension'],case_id,interval,dispatcherKPI)\n",
    "            \n",
    "            criteria.append(\"filterWithinRange\")\n",
    "            if filteredWithinRange.empty==False:\n",
    "                filters[tuple(criteria)]=filteredWithinRange\n",
    "                \n",
    "            criteria2=list(row['Dimension'])\n",
    "            criteria2.append(row['function'])\n",
    "            criteria2.append(row['interestValue'])\n",
    "            criteria2.append(str(interval))\n",
    "            criteria2.append(\"filterNotInRange\")\n",
    "            filteredNotInRange=filterCasesNotInRange(log_ct,row['Dimension'],case_id,interval,dispatcherKPI)\n",
    "            if filteredNotInRange.empty==False:\n",
    "                filters[tuple(criteria2)]=filteredNotInRange\n",
    "        else:\n",
    "            criteria=list(row['Dimension'])\n",
    "            criteria.append(row['function'])\n",
    "            criteria.append(row['interestValue'])\n",
    "            criteria.append(row['concreteValue'])\n",
    "            filteredWithout=filterCasesWithoutDiscreteValues(log_ct,row['Dimension'][1],\"case:id\",[row['concreteValue']])\n",
    "            criteria.append(\"filterWithout\")\n",
    "            if filteredWithout.empty==False:\n",
    "                filters[tuple(criteria)]=filteredWithout\n",
    "            \n",
    "            criteria2=list(row['Dimension'])\n",
    "            criteria2.append(row['function'])\n",
    "            criteria2.append(row['interestValue'])\n",
    "            criteria2.append(row['concreteValue'])\n",
    "            criteria2.append(\"filterWith\")\n",
    "            filteredWith=filterCasesWithDiscreteValues(log_ct,row['Dimension'][1],\"case:id\",[row['concreteValue']])\n",
    "            if filteredWith.empty==False:\n",
    "                filters[tuple(criteria2)]=filteredWith\n",
    "            \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_type(s):\n",
    "    \"\"\"Parse interval string to Interval\"\"\"\n",
    "    \n",
    "    table = str.maketrans({'[': '(', ']': ')'})\n",
    "    left_closed = s.startswith('[')\n",
    "    right_closed = s.endswith(']')\n",
    "\n",
    "    left, right = ast.literal_eval(s.translate(table))\n",
    "\n",
    "    t = 'neither'\n",
    "    if left_closed and right_closed:\n",
    "        t = 'both'\n",
    "    elif left_closed:\n",
    "        t = 'left'\n",
    "    elif right_closed:\n",
    "        t = 'right'\n",
    "\n",
    "    return pd.Interval(left, right, closed=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCasesWithinRange(df,dim,case_id,interval,dispatcher):\n",
    "    \"\"\"Filter cases that are not included in a range\"\"\"\n",
    "    fun=dispatcher[dim[0]]\n",
    "    #interval_type(dataShapley['concreteValue'][0])\n",
    "    dfs=df.groupby(case_id).apply(lambda x: fun(x,dim[1],dim[2])).reset_index()\n",
    "    casesInRange=[]\n",
    "    for index, row in dfs.iterrows():\n",
    "        if row[0] in interval:\n",
    "            casesInRange.append(row['case:id'])\n",
    "        \n",
    "    casesInRange=list(set(casesInRange))\n",
    "    \n",
    "    filteredCases=df[df[case_id].isin(casesInRange)]\n",
    "    \n",
    "    return filteredCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCasesNotInRange(df,dim,case_id,interval,dispatcher):\n",
    "    \"\"\"\n",
    "    Filter cases that are not included in a range\n",
    "    \"\"\"\n",
    "    fun=dispatcher[dim[0]]\n",
    "    #interval_type(dataShapley['concreteValue'][0])\n",
    "    dfs=df.groupby(case_id).apply(lambda x: fun(x,dim[1],dim[2])).reset_index()\n",
    "    casesNotInRange=[]\n",
    "    for index, row in dfs.iterrows():\n",
    "        if row[0] not in interval:\n",
    "            casesNotInRange.append(row['case:id'])\n",
    "        \n",
    "    casesNotInRange=list(set(casesNotInRange))\n",
    "    \n",
    "    filteredCases=df[df[case_id].isin(casesNotInRange)]\n",
    "    \n",
    "    return filteredCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupCasesNumericValues(df,dim,case_id,interval,dispatcher):\n",
    "    \n",
    "    \"\"\"Group cases depending on whether they are included or not in a range\"\"\"\n",
    "    fun=dispatcher[dim[0]]\n",
    "\n",
    "    #interval_type(dataShapley['concreteValue'][0])\n",
    "    dfs=df.groupby(case_id).apply(lambda x: fun(x,dim[1],dim[2])).reset_index()\n",
    "    casesInRange=[]\n",
    "    casesNotInRange=[]\n",
    "    for index, row in dfs.iterrows():\n",
    "        if interval.contains(row[0])==False:\n",
    "            casesNotInRange.append(row['case:id'])\n",
    "        else:\n",
    "            casesInRange.append(row['case:id'])\n",
    "        \n",
    "    casesInRange=list(set(casesInRange))\n",
    "    casesNotInRange=list(set(casesNotInRange))\n",
    "    \n",
    "    filteredCasesInRange=df[df[case_id].isin(casesInRange)]\n",
    "    filteredCasesInRange['Value']=[True for i in range(0,filteredCasesInRange.shape[0])]\n",
    "    \n",
    "    filteredCasesNotInRange=df[df[case_id].isin(casesNotInRange)]\n",
    "    filteredCasesNotInRange['Value']=[False for i in range(0,filteredCasesNotInRange.shape[0])]\n",
    "    \n",
    "    return filteredCasesInRange,filteredCasesNotInRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupCasesDiscreteValue(df,dim,case_id,value,dispatcher):\n",
    "    \"\"\"Group cases depending on wheter they include or not a discrete value such as resource\"\"\"\n",
    "    fun=dispatcher[dim[0]]\n",
    "    \n",
    "    dfs=df.groupby(case_id).apply(lambda x: x[dim[1]]).reset_index()\n",
    "    casesWithDiscreteValue=[]\n",
    "    casesWithoutDiscreteValue=[]\n",
    "    \n",
    "    for index, row in dfs.iterrows():\n",
    "        \n",
    "        if value in index:#if \n",
    "            casesWithDiscreteValue.append(row['case:id'])\n",
    "        else:\n",
    "            casesWithoutDiscreteValue.append(row['case:id'])\n",
    "        \n",
    "    casesWithDiscreteValue=list(set(casesWithDiscreteValue))\n",
    "    casesWithoutDiscreteValue=list(set(casesWithoutDiscreteValue))\n",
    "    \n",
    "    filteredCasesWithDiscreteValue=df[df[case_id].isin(casesWithDiscreteValue)]\n",
    "    filteredCasesWithoutDiscreteValue=df[df[case_id].isin(casesWithoutDiscreteValue)]\n",
    "    \n",
    "    return filteredCasesWithDiscreteValue,filteredCasesWithoutDiscreteValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCasesWithoutDiscreteValues(df,field,case_id,values):\n",
    "    \"\"\"\n",
    "    This function filters the cases of a log, which do not exist an activity or multiple activities\n",
    "    \n",
    "    Inputs:\n",
    "    df: dataframe which represents the log\n",
    "    activities: column of the dataframe which contain the activities\n",
    "    case_id: name of the column of the activities in the dataframe\n",
    "    values: values that must not occur\n",
    "    \n",
    "    Output:\n",
    "    Cases which do not have that pattern\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #df[activities]->column which represents the activities\n",
    "    #df[activities].isin(acts)->checks which values are contained in the array of activities that must not occur\n",
    "    #df[df[activities].isin(acts)]-> filter the rows which accomplished the previous condition \n",
    "    #df[df[activities].isin(acts)][case_id].unique()-> get the case_ids (without repetition) of the filtered rows\n",
    "    case_id_no_validos4=df[df[field].isin(values)][case_id].unique()\n",
    "    \n",
    "    #filter the rows whose case IDs are not in the invalid case IDs\n",
    "    case_id_validos4=df[~df[case_id].isin(case_id_no_validos4)][case_id].unique()\n",
    "    df_filtrado4=df[df[case_id].isin(case_id_validos4)]#filter the rows of the cases that do not contain that activities\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_filtrado4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCasesWithDiscreteValues(df,field,case_id,values):\n",
    "    \"\"\"\n",
    "    This function filters the cases of a log, which do not exist an activity or multiple activities\n",
    "    \n",
    "    Inputs:\n",
    "    df: dataframe which represents the log\n",
    "    activities: column of the dataframe which contain the activities\n",
    "    case_id: name of the column of the activities in the dataframe\n",
    "    values: values that must occur\n",
    "    \n",
    "    Output:\n",
    "    Cases which do not have that pattern\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #df[activities]->column which represents the activities\n",
    "    #df[activities].isin(acts)->checks which values are contained in the array of activities that must not occur\n",
    "    #df[df[activities].isin(acts)]-> filter the rows which accomplished the previous condition \n",
    "    #df[df[activities].isin(acts)][case_id].unique()-> get the case_ids (without repetition) of the filtered rows\n",
    "    case_id_validos4=df[df[field].isin(values)][case_id].unique()\n",
    "    \n",
    "    #filter the rows whose case IDs are in the valid case IDs\n",
    "    df_filtrado4=df[df[case_id].isin(case_id_validos4)]#filter the rows of the cases that do not contain that activities\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_filtrado4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
